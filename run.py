import subprocess
import time
import os

def launch_llama_model(model="llama3.1:latest"):
    if os.getenv("USE_OLLAMA_HTTP", "false").lower() == "true":
        return

    try:
        print(f"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–¥–µ–ª—å LLM: {model}")
        subprocess.Popen(["ollama", "run", model], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        time.sleep(2)
    except Exception as e:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å –º–æ–¥–µ–ª—å: {e}")

if __name__ == "__main__":
    from app.main import main
    from dotenv import load_dotenv

    load_dotenv()
    launch_llama_model()
    main()
